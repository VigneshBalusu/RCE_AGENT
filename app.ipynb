{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37c8461f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5 (Fixed): Master Ingestion with Header Injection\n",
    "import os\n",
    "import glob\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03a93a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Setup Embeddings\n",
    "print(\"üì• Loading Hugging Face Embedding Model...\")\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# 2. Define Splitter\n",
    "headers_to_split_on = [\n",
    "    (\"#\", \"DocName\"),\n",
    "    (\"##\", \"Section\"),\n",
    "    (\"###\", \"SubSection\"),\n",
    "]\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e33278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Process Files\n",
    "all_splits = []\n",
    "data_folder = \"data\"\n",
    "md_files = glob.glob(os.path.join(data_folder, \"*.md\"))\n",
    "\n",
    "print(f\"üìÇ Found {len(md_files)} Markdown files.\")\n",
    "\n",
    "for file_path in md_files:\n",
    "    try:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            file_content = f.read()\n",
    "            \n",
    "        splits = markdown_splitter.split_text(file_content)\n",
    "        \n",
    "        # --- THE FIX STARTS HERE ---\n",
    "        for split in splits:\n",
    "            # 1. Add Source Metadata\n",
    "            split.metadata[\"source\"] = file_path\n",
    "            \n",
    "            # 2. INJECT Metadata back into Content\n",
    "            # We construct a \"Context String\" from the headers\n",
    "            header_context = \"\"\n",
    "            if \"Section\" in split.metadata:\n",
    "                header_context += f\"Section: {split.metadata['Section']}\\n\"\n",
    "            if \"SubSection\" in split.metadata:\n",
    "                header_context += f\"Role/Topic: {split.metadata['SubSection']}\\n\"\n",
    "            \n",
    "            # Prepend it to the actual text\n",
    "            split.page_content = header_context + split.page_content\n",
    "        # --- THE FIX ENDS HERE ---\n",
    "            \n",
    "        all_splits.extend(splits)\n",
    "        print(f\"   ‚úÖ Processed {os.path.basename(file_path)} -> {len(splits)} chunks.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Error reading {file_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44825566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Re-create Database (Clean Start)\n",
    "import shutil\n",
    "if os.path.exists(\"./chroma_db\"):\n",
    "    shutil.rmtree(\"./chroma_db\")\n",
    "    print(\"   üóëÔ∏è  Cleared old database.\")\n",
    "\n",
    "print(f\"‚è≥ Ingesting {len(all_splits)} chunks...\")\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents=all_splits,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=\"./chroma_db\"\n",
    ")\n",
    "print(\"üéâ Database Updated! Headers are now visible to the AI.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c01b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: The \"Best of Both Worlds\" - Hybrid Search\n",
    "from langchain_classic.retrievers import EnsembleRetriever\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "\n",
    "# 1. Setup Vector Retriever (The \"Concept\" Brain)\n",
    "# k=3 finds general matches like \"Dean of Research\"\n",
    "vector_retriever = vectordb.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "# 2. Setup Keyword Retriever (The \"Exact Match\" Brain)\n",
    "# We fetch all docs from the DB to build the keyword index\n",
    "raw_docs = vectordb.similarity_search(\"dummy\", k=100) \n",
    "bm25_retriever = BM25Retriever.from_documents(raw_docs)\n",
    "bm25_retriever.k = 3\n",
    "\n",
    "# 3. Create the Hybrid (Ensemble)\n",
    "# weights=[0.5, 0.5] means we trust both brains equally\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, vector_retriever],\n",
    "    weights=[0.5, 0.5]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87f5c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"‚úÖ Hybrid System Online: Vectors + Keywords\")\n",
    "\n",
    "# 4. FINAL TEST: \"Tell me about Ranga\"\n",
    "query = \"top companies for placments\"\n",
    "print(f\"\\nüîé HYBRID SEARCH FOR: '{query}'\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "results = ensemble_retriever.invoke(query)\n",
    "\n",
    "for i, doc in enumerate(results):\n",
    "    print(f\"üîπ Result #{i+1}\")\n",
    "    print(\"Source: \",doc.metadata['source'])\n",
    "    # Check source to see which brain found it (BM25 usually finds names)\n",
    "    print(f\"   üìÑ Content: {doc.page_content}...\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640cc512",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b656ddad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
